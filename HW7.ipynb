{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930d3b1-275c-491d-9274-aee300e7a5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape after cleaning: (714, 6)\n",
      "\n",
      "Unique values per column:\n",
      "Survived      2\n",
      "Sex           2\n",
      "Age          88\n",
      "Fare        220\n",
      "Pclass_2      2\n",
      "Pclass_3      2\n",
      "dtype: int64\n",
      "\n",
      "Feature matrix shape: (714, 5)\n",
      "Target vector shape: (714,)\n",
      "Feature matrix dtype: float64 | Target vector dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [betas]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='11737' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      97.81% [11737/12000 00:19&lt;00:00 Sampling 4 chains, 5,722 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. Imports & Setup\n",
    "# ---------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Load & Basic Cleaning\n",
    "# ---------------------------------------------------------\n",
    "# Adjust the file path as needed\n",
    "df = pd.read_csv(\"Titanic-Dataset.csv\")\n",
    "\n",
    "# Keep only the needed columns\n",
    "cols_needed = [\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"Fare\"]\n",
    "df = df[cols_needed].copy()\n",
    "\n",
    "# Drop rows with missing values in these columns\n",
    "df.dropna(subset=cols_needed, inplace=True)\n",
    "\n",
    "# Convert 'Sex' to numeric: 1 = male, 0 = female\n",
    "df[\"Sex\"] = (df[\"Sex\"] == \"male\").astype(int)\n",
    "\n",
    "# One-hot encode 'Pclass', but drop_first=True to avoid perfect collinearity\n",
    "df = pd.get_dummies(df, columns=[\"Pclass\"], prefix=\"Pclass\", drop_first=True)\n",
    "# This will create (for a 3-class variable) only 2 columns, e.g. Pclass_2 and Pclass_3.\n",
    "# Pclass_1 is implied as the baseline.\n",
    "\n",
    "# Force numeric dtypes (just in case)\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Drop rows that might have become NaN\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Check final shape and unique values\n",
    "print(\"DataFrame shape after cleaning:\", df.shape)\n",
    "print(\"\\nUnique values per column:\")\n",
    "print(df.nunique())\n",
    "\n",
    "# If any column has only 1 unique value, it won't help the model.\n",
    "# For example:\n",
    "# for col in df.columns:\n",
    "#     if df[col].nunique() == 1:\n",
    "#         print(f\"Column '{col}' is constant and will be removed.\")\n",
    "#         df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Define X (features) and y (target)\n",
    "# ---------------------------------------------------------\n",
    "# Target\n",
    "y = df[\"Survived\"].astype(int).values\n",
    "\n",
    "# Example features:\n",
    "#   Sex, Age, Fare, Pclass_2, Pclass_3\n",
    "X_cols = [\"Sex\", \"Age\", \"Fare\", \"Pclass_2\", \"Pclass_3\"]\n",
    "for c in X_cols:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing expected column '{c}' in DataFrame.\")\n",
    "\n",
    "X = df[X_cols].astype(float).values\n",
    "\n",
    "print(\"\\nFeature matrix shape:\", X.shape)\n",
    "print(\"Target vector shape:\", y.shape)\n",
    "print(\"Feature matrix dtype:\", X.dtype, \"| Target vector dtype:\", y.dtype)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Build & Sample from Bayesian Logistic Model\n",
    "# ---------------------------------------------------------\n",
    "with pm.Model() as logistic_model:\n",
    "    # Priors on coefficients\n",
    "    betas = pm.Normal(\"betas\", mu=0, sigma=1, shape=X.shape[1])\n",
    "    \n",
    "    # Linear predictor\n",
    "    eta = pm.math.dot(X, betas)\n",
    "    \n",
    "    # Logistic transformation\n",
    "    p = pm.Deterministic(\"p\", pm.math.sigmoid(eta))\n",
    "    \n",
    "    # Bernoulli likelihood\n",
    "    y_obs = pm.Bernoulli(\"y_obs\", p=p, observed=y)\n",
    "    \n",
    "    # MCMC sampling\n",
    "    trace = pm.sample(\n",
    "        draws=2000,       # Posterior draws\n",
    "        tune=1000,        # Warm-up\n",
    "        target_accept=0.9,\n",
    "        random_seed=42\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Posterior Summaries & Diagnostics\n",
    "# ---------------------------------------------------------\n",
    "summary = az.summary(trace, var_names=[\"betas\"], round_to=2)\n",
    "print(\"\\nPosterior Summary for 'betas':\")\n",
    "display(summary)\n",
    "\n",
    "# Trace plot\n",
    "az.plot_trace(trace, var_names=[\"betas\"])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64d79bbe-93df-43ed-9dce-3a2d52f5d42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Columns in the dataset ===\n",
      "['school,sex,age,address,famsize,Pstatus,Medu,Fedu,Mjob,Fjob,reason,guardian,traveltime,studytime,failures,schoolsup,famsup,paid,activities,nursery,higher,internet,romantic,famrel,freetime,goout,Dalc,Walc,health,absences,G1,G2,G3']\n",
      "\n",
      "WARNING: The following columns are missing: ['G1', 'G2', 'studytime', 'failures', 'age', 'absences']\n",
      "Adjust your 'cols_needed' to match the actual column names in your CSV.\n",
      "\n",
      "=== Final shape after subsetting & downsampling ===\n",
      "(100, 1)\n",
      "  school,sex,age,address,famsize,Pstatus,Medu,Fedu,Mjob,Fjob,reason,guardian,traveltime,studytime,failures,schoolsup,famsup,paid,activities,nursery,higher,internet,romantic,famrel,freetime,goout,Dalc,Walc,health,absences,G1,G2,G3\n",
      "0  GP,M,17,U,GT3,T,2,1,other,other,home,mother,2,...                                                                                                                                                                                 \n",
      "1  MS,M,18,R,LE3,T,1,2,at_home,services,other,fat...                                                                                                                                                                                 \n",
      "2  GP,M,18,R,LE3,T,3,3,other,services,course,moth...                                                                                                                                                                                 \n",
      "3  GP,F,16,U,GT3,A,2,1,other,other,other,mother,1...                                                                                                                                                                                 \n",
      "4  MS,M,20,U,LE3,A,2,2,services,services,course,o...                                                                                                                                                                                 \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('G1', 'G2')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('G1', 'G2')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 46\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# 4. Define Outcomes (Y) and Predictors (X)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Two continuous outcomes\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mG1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mG2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# shape: (n, 2)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Four predictors\u001b[39;00m\n\u001b[1;32m     49\u001b[0m X_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudytime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailures\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsences\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: ('G1', 'G2')"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------\n",
    "# 1. Imports & Setup\n",
    "# -----------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional: nicer plot style\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Load Data & Inspect Columns\n",
    "# -----------------------------------------------------\n",
    "df = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "\n",
    "print(\"=== Columns in the dataset ===\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "\n",
    "# Check if any columns are missing\n",
    "missing_cols = [c for c in cols_needed if c not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"\\nWARNING: The following columns are missing: {missing_cols}\")\n",
    "    print(\"Adjust your 'cols_needed' to match the actual column names in your CSV.\")\n",
    "else:\n",
    "    print(\"\\nAll required columns found!\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. Subset & Clean Data\n",
    "# -----------------------------------------------------\n",
    "\n",
    "\n",
    "# Optional: downsample to 100 rows for faster demonstration\n",
    "df = df.sample(n=100, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Final shape after subsetting & downsampling ===\")\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. Define Outcomes (Y) and Predictors (X)\n",
    "# -----------------------------------------------------\n",
    "# Two continuous outcomes\n",
    "Y = df[\"G1\", \"G2\"].values  # shape: (n, 2)\n",
    "\n",
    "# Four predictors\n",
    "X_cols = [\"studytime\", \"failures\", \"age\", \"absences\"]\n",
    "X = df[X_cols].values        # shape: (n, 4)\n",
    "\n",
    "print(\"\\nY shape:\", Y.shape)  # (100, 2) if you downsampled\n",
    "print(\"X shape:\", X.shape)    # (100, 4)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Build & Sample from Bayesian Multivariate Model\n",
    "# -----------------------------------------------------\n",
    "# We'll assume Y ~ MvNormal(mu, Sigma), where:\n",
    "#   mu = X * betas + intercept\n",
    "#   betas: shape (4, 2)\n",
    "#   intercept: shape (2,)\n",
    "#   Sigma is built from an LKJ prior for correlation + scale for each dimension\n",
    "\n",
    "with pm.Model() as multivariate_model:\n",
    "    # Regression coefficients: (p, m)\n",
    "    betas = pm.Normal(\"betas\", mu=0, sigma=1, shape=(X.shape[1], Y.shape[1]))\n",
    "    \n",
    "    # Intercept: one per outcome dimension\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=1, shape=Y.shape[1])\n",
    "    \n",
    "    # Linear predictor\n",
    "    mu = pm.math.dot(X, betas) + intercept  # shape (n, 2)\n",
    "    \n",
    "    # Covariance structure\n",
    "    # sigma = marginal std dev for each outcome\n",
    "    sigma = pm.Exponential(\"sigma\", 1.0, shape=Y.shape[1])\n",
    "    # LKJ prior for correlation\n",
    "    Lcorr = pm.LKJCholeskyCov(\"Lcorr\", n=Y.shape[1], eta=2.0, \n",
    "                              sd_dist=pm.Exponential.dist(1.0))\n",
    "    \n",
    "    # Construct the full Cholesky factor\n",
    "    chol = pm.Deterministic(\"chol\", pm.diag(sigma) @ Lcorr)\n",
    "    \n",
    "    # Multivariate Normal likelihood\n",
    "    y_obs = pm.MvNormal(\"y_obs\", mu=mu, chol=chol, observed=Y)\n",
    "    \n",
    "    # MCMC sampling\n",
    "    trace = pm.sample(\n",
    "        draws=2000, \n",
    "        tune=1000, \n",
    "        target_accept=0.9, \n",
    "        random_seed=42\n",
    "    )\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. Posterior Summary & Diagnostics\n",
    "# -----------------------------------------------------\n",
    "summary = az.summary(trace, var_names=[\"betas\", \"intercept\", \"sigma\", \"Lcorr\"], round_to=2)\n",
    "print(\"\\n=== Posterior Summary ===\")\n",
    "display(summary)\n",
    "\n",
    "# Trace plots\n",
    "az.plot_trace(trace, var_names=[\"betas\", \"intercept\", \"sigma\"])\n",
    "plt.show()\n",
    "\n",
    "# (Optional) Pair plot for correlation parameters\n",
    "az.plot_pair(trace, var_names=[\"sigma\", \"Lcorr\"], divergences=True, kind=\"kde\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb485ea-62de-4db7-b3c2-3be6350051eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Attrition', 'Overtime', 'MonthlyIncome', 'YearsAtCompany'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 2. Subset & Clean\u001b[39;00m\n\u001b[1;32m     21\u001b[0m all_needed \u001b[38;5;241m=\u001b[39m binary_outcomes \u001b[38;5;241m+\u001b[39m predictors\n\u001b[0;32m---> 22\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_needed\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 3. Define X (predictors) and Y (binary outcomes)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m Y \u001b[38;5;241m=\u001b[39m df[binary_outcomes]\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# shape (n, 2)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6116\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6118\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6177\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6178\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Attrition', 'Overtime', 'MonthlyIncome', 'YearsAtCompany'] not in index\""
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Complete Bayesian Multivariate Classification in One Code Chunk\n",
    "# =========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv(\"Employee.csv\")\n",
    "\n",
    "# Example columns:\n",
    "#   - Two binary outcomes: \"Attrition\" (0/1), \"Overtime\" (0/1)\n",
    "#   - Predictors: \"Age\", \"MonthlyIncome\", \"YearsAtCompany\"\n",
    "binary_outcomes = [\"Attrition\", \"Overtime\"]\n",
    "predictors = [\"Age\", \"MonthlyIncome\", \"YearsAtCompany\"]\n",
    "\n",
    "# 2. Subset & Clean\n",
    "all_needed = binary_outcomes + predictors\n",
    "df = df[all_needed].dropna()\n",
    "\n",
    "# 3. Define X (predictors) and Y (binary outcomes)\n",
    "Y = df[binary_outcomes].values  # shape (n, 2)\n",
    "X = df[predictors].values      # shape (n, 3)\n",
    "\n",
    "# (Optional) Downsample for demonstration\n",
    "n_desired = 200  # choose how many rows to keep\n",
    "if X.shape[0] > n_desired:\n",
    "    idx = np.random.choice(X.shape[0], n_desired, replace=False)\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "\n",
    "# (Optional) Scale numeric predictors\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 4. PyMC Model: Latent-Variable Multivariate Classification\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "n, m = Y.shape\n",
    "p = X.shape[1]\n",
    "\n",
    "with pm.Model() as multi_label_model:\n",
    "    # Coefficients: shape=(p, m)\n",
    "    betas = pm.Normal(\"betas\", mu=0, sigma=1, shape=(p, m))\n",
    "    \n",
    "    # Intercepts: shape=(m,)\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=1, shape=m)\n",
    "    \n",
    "    # Covariance via LKJ prior\n",
    "    sigma = pm.Exponential(\"sigma\", 1.0, shape=m)\n",
    "    Lcorr = pm.LKJCholeskyCov(\"Lcorr\", n=m, eta=2.0,\n",
    "                              sd_dist=pm.Exponential.dist(1.0))\n",
    "    chol = pm.Deterministic(\"chol\", pm.diag(sigma) @ Lcorr)\n",
    "    \n",
    "    # Mean of latent variable: mu = X * betas + intercept\n",
    "    mu = pm.math.dot(X, betas) + intercept  # shape (n, m)\n",
    "    \n",
    "    # Latent variable z ~ MvNormal\n",
    "    z = pm.MvNormal(\"z\", mu=mu, chol=chol, shape=(n, m))\n",
    "    \n",
    "    # Logistic link => p = sigmoid(z)\n",
    "    p_ = pm.Deterministic(\"p\", pm.math.sigmoid(z))\n",
    "    \n",
    "    # Observed binary outcomes\n",
    "    y_obs = pm.Bernoulli(\"y_obs\", p=p_, observed=Y)\n",
    "    \n",
    "    # MCMC sampling\n",
    "    trace = pm.sample(draws=2000, tune=1000, target_accept=0.9, random_seed=42)\n",
    "\n",
    "# 5. Posterior Summary & Diagnostics\n",
    "summary = az.summary(trace, var_names=[\"betas\", \"intercept\", \"sigma\", \"Lcorr\"], round_to=2)\n",
    "print(\"\\n=== Posterior Summary ===\")\n",
    "print(summary)\n",
    "\n",
    "az.plot_trace(trace, var_names=[\"betas\", \"intercept\", \"sigma\"])\n",
    "plt.show()\n",
    "\n",
    "az.plot_pair(trace, var_names=[\"sigma\", \"Lcorr\"], divergences=True, kind=\"kde\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
